{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4550eca6-5b20-41c9-99c8-0e07e4a6f731",
   "metadata": {},
   "source": [
    "## Understanding inner function of NN through Logistic Regression Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591582ee-477e-427d-b4d2-1797952d448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b01b9-51ce-47f8-94d2-1ebab00a038a",
   "metadata": {},
   "source": [
    "### 1. read files from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b6551-421f-460e-a891-9c4e48a33cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('train_catvnoncat.h5', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af336fd2-8bbc-4103-8d15-109c71188c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = h5py.File('test_catvnoncat.h5', \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba4c84-3e0c-48e6-b48d-81d00e045c77",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "Find the values for:\n",
    "\n",
    "m_train (number of training examples)\n",
    "m_test (number of test examples)\n",
    "num_px (= height = width of a training image) Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a105c2-f6cf-4bbe-a64f-74ca79bd3009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb20b38-d33d-45ab-9b0e-c49b3aa75ff2",
   "metadata": {},
   "source": [
    "### Get the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628830aa-a7e9-44f2-bcb6-221fb15e5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5dba25-2344-4bc8-8718-12759e58fd7c",
   "metadata": {},
   "source": [
    "### Plot an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2ecb0-043d-4f21-b48f-a69c2d47df93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36fefb22-9d66-4cff-8ad4-fa0a98922cc6",
   "metadata": {},
   "source": [
    "### 2. Reshape/flatten a matrix\n",
    "**Exercise 2:**\n",
    "\n",
    "Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px, num_px, 3, 1).\n",
    "\n",
    "A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape ($b*c*d$, a) is to use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebed79-4cd6-435b-a314-a5aa1f84473d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88710e43-2d14-41d3-8f1f-4f80204e387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "#print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "#print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e20c7-3cf1-4ffb-a91b-49c35ec7ddc2",
   "metadata": {},
   "source": [
    "### 3. Scale the dataset\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
    "\n",
    "One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c48fc0-922c-4921-a64d-7bb97250aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ef53a-e2c8-4ecb-a430-f221ffa491a4",
   "metadata": {},
   "source": [
    "### 4 - Building the parts of our algorithm\n",
    "The main steps for building a Neural Network are:\n",
    "\n",
    "1. Define the model structure (such as number of input features)\n",
    "2. Initialize the model's parameters\n",
    "3. Loop:\n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "\n",
    "You often build 1-3 separately and integrate them into one function we call model().\n",
    "\n",
    "### 4.1 Helper function- Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b07a9-00c0-4e40-a362-a19c49e55098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c81f3c-e683-4073-9b1a-3c731f308931",
   "metadata": {},
   "source": [
    "### 4.2 Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021509af-e9b3-4e8a-8ac0-d5cd5a04705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "\n",
    "    b#code here\n",
    "\n",
    "    #####\n",
    "\n",
    "    #check the dimension\n",
    "    assert(w.shape == (dim, 1) )\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6a71a-9c3c-445d-94bc-2c29813c41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify\n",
    "w, b = initialize_with_zeros(3)\n",
    "print(\"w \" + str(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c28d1-1f97-472c-8f27-8028d26004fd",
   "metadata": {},
   "source": [
    "### 4.3 FP and BP\n",
    "\n",
    "**Forward Propagation:**\n",
    "- Get X,\n",
    "- Compute $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$,\n",
    "- Cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\"\n",
    "  \n",
    "**Back Propagation:** \n",
    "    Here are the two formulas you will be using:\"\n",
    "\n",
    "- $\\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$,\n",
    "- $ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df479834-b2a8-4a1d-a012-51ef9d730a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    #no of examples\n",
    "    m = X.shape[1]\n",
    "\n",
    "    #Forward Propagation   (CODE HERE - 2 lines) \n",
    "    A = \n",
    "    J = \n",
    "      \n",
    "\n",
    "    # Back Propagation (CODE HERE - 2 lines) \n",
    "    dw = \n",
    "    db = \n",
    "\n",
    "\n",
    "    #dimension check\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    #print(\"*****propagate completed ***********\")\n",
    "\n",
    "    return grads, J\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bd4d9-9c15-4ef1-9937-befdc20cfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the function\n",
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192459b-808a-4bed-aace-75fad3c4af45",
   "metadata": {},
   "source": [
    "```\n",
    "dw = [[0.99845601] [2.39507239]]\n",
    " ```\n",
    " \n",
    "db = 0.001455578136784208\n",
    "cost = 5.801545319394553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b211b41-1db2-4d0e-a542-0c1234f896fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
